{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOm5oni1rKe0pPRwX4GCDf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bryan-Az/RL-DQN-Gym/blob/main/DQN_projects/%5BFinal_Evaluation_and_Continued_Training%5D_Deep_Reinforcement_Learning_via_Neural_Network_Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG071bmtVFFf"
      },
      "source": [
        "# **Deep Q-Learning Network (DQN) Reinforcement Learning Agent for Blackjack**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtUvlSMpqHc-"
      },
      "source": [
        "## Imports and Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ancPCGb9eX9A"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# capture line is to hide the output\n",
        "# Install required packages\n",
        "!pip install gymnasium torch numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uLMCIhrzSIyj"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lum8T1EmWGpY"
      },
      "source": [
        "## **DQN Agent with Replay Memory Implementation**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import namedtuple, deque\n",
        "\n",
        "# Define a named tuple to store experiences\n",
        "Experience = namedtuple('Experience', ('state', 'action', 'reward', 'next_state', 'done'))\n",
        "\n",
        "class ReplayMemory:\n",
        "    def __init__(self, capacity=10000):\n",
        "        self.memory = deque(maxlen=capacity)\n",
        "        self.capacity = capacity\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Save an experience to memory\"\"\"\n",
        "        experience = Experience(state, action, reward, next_state, done)\n",
        "        self.memory.append(experience)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        \"\"\"Randomly sample a batch of experiences from memory\"\"\"\n",
        "        if batch_size > len(self.memory):\n",
        "            batch_size = len(self.memory)\n",
        "        experiences = random.sample(self.memory, batch_size)\n",
        "\n",
        "        # Convert to separate arrays\n",
        "        states = torch.FloatTensor([exp.state for exp in experiences])\n",
        "        actions = torch.LongTensor([exp.action for exp in experiences])\n",
        "        rewards = torch.FloatTensor([exp.reward for exp in experiences])\n",
        "        next_states = torch.FloatTensor([exp.next_state for exp in experiences])\n",
        "        dones = torch.FloatTensor([exp.done for exp in experiences])\n",
        "\n",
        "        return states, actions, rewards, next_states, dones\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "class ImprovedDQNAgent:\n",
        "    def __init__(self, input_dim=3, learning_rate=5e-4, gamma=0.99, epsilon=1.0):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.fitness = [] # used to store a series of 'avg reward' during evaluation\n",
        "\n",
        "        # Larger network\n",
        "        self.policy_net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 2)\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.target_net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 2)\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "\n",
        "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=learning_rate)\n",
        "        self.memory = ReplayMemory(capacity=20000)\n",
        "\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_min = 0.05\n",
        "        self.epsilon_decay = 0.99997\n",
        "        self.batch_size = 128\n",
        "        self.target_update = 10\n",
        "        self.episode_count = 0\n",
        "\n",
        "    def select_action(self, state):\n",
        "        \"\"\"Select action using epsilon-greedy policy\"\"\"\n",
        "        if random.random() < self.epsilon:\n",
        "            return random.randint(0, 1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            state = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
        "            q_values = self.policy_net(state)\n",
        "            return q_values.argmax().item()\n",
        "\n",
        "    def update_epsilon(self):\n",
        "        \"\"\"Decay epsilon value\"\"\"\n",
        "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
        "\n",
        "    def store_transition(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Store transition in replay memory\"\"\"\n",
        "        self.memory.push(state, action, reward, next_state, done)\n",
        "\n",
        "    def train_step(self):\n",
        "        \"\"\"Perform one training step\"\"\"\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return\n",
        "\n",
        "        states, actions, rewards, next_states, dones = self.memory.sample(self.batch_size)\n",
        "        states = states.to(self.device)\n",
        "        actions = actions.to(self.device)\n",
        "        rewards = rewards.to(self.device)\n",
        "        next_states = next_states.to(self.device)\n",
        "        dones = dones.to(self.device)\n",
        "\n",
        "        # Double DQN implementation\n",
        "        with torch.no_grad():\n",
        "            next_actions = self.policy_net(next_states).argmax(1)\n",
        "            next_q_values = self.target_net(next_states).gather(1, next_actions.unsqueeze(1)).squeeze(1)\n",
        "            target_q_values = rewards + (1 - dones.float()) * self.gamma * next_q_values\n",
        "\n",
        "        current_q_values = self.policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
        "\n",
        "        # Huber loss for better stability\n",
        "        loss = nn.SmoothL1Loss()(current_q_values, target_q_values)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), 1.0)\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def update_target_network(self):\n",
        "        \"\"\"Update target network parameters\"\"\"\n",
        "        if self.episode_count % self.target_update == 0:\n",
        "            self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "        self.episode_count += 1"
      ],
      "metadata": {
        "id": "v_2UYM5EWDE2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the improved agent then loading the state dict from the .pth file\n",
        "DQN_Agent = ImprovedDQNAgent()\n",
        "DQN_Agent.policy_net.load_state_dict(torch.load('/content/Blackjack_DQN_500000_episodes.pth')['policy_net_state_dict'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZGDNPckWZ0I",
        "outputId": "4a06f3e0-c57a-4175-aa37-87c88c2edf5d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-6ea958eb1ffb>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  DQN_Agent.policy_net.load_state_dict(torch.load('/content/Blackjack_DQN_500000_episodes.pth')['policy_net_state_dict'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "XcpUXf7qa47U"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aUHVllYjxmR"
      },
      "source": [
        "### Evaluation Metrics of the Trained Model on a New Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "r_EumUs-fk_8"
      },
      "outputs": [],
      "source": [
        "test_env = gym.make(\"Blackjack-v1\", render_mode='rgb_array')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4Z1zz0vikvC",
        "outputId": "9b85370f-578f-4762-e45d-dacc6f4260ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating trained agent...\n",
            "\n",
            "Detailed Evaluation Results:\n",
            "Number of Episodes: 200\n",
            "Win Rate: 38.5%  (77/200)\n",
            "Draw Rate: 14.0%  (28/200)\n",
            "Loss Rate: 47.5%  (95/200)\n",
            "Average Reward: -0.090\n",
            "Average Final Player Sum: 19.6\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the trained agent\n",
        "def evaluate_agent_detailed(test_env, trained_agent, n_episodes=200):\n",
        "    wins = 0\n",
        "    draws = 0\n",
        "    losses = 0\n",
        "    total_rewards = []\n",
        "    player_sums = []\n",
        "    dealer_sums = []\n",
        "\n",
        "    for episode in range(n_episodes):\n",
        "        state, _ = test_env.reset()\n",
        "        done = False\n",
        "        episode_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            # Use greedy policy (no exploration)\n",
        "            with torch.no_grad():\n",
        "                state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "                action = trained_agent.policy_net(state_tensor).argmax().item()\n",
        "\n",
        "            state, reward, done, truncated, _ = test_env.step(action)\n",
        "            episode_reward += reward\n",
        "\n",
        "        total_rewards.append(episode_reward)\n",
        "        if reward > 0:\n",
        "            wins += 1\n",
        "        elif reward == 0:\n",
        "            draws += 1\n",
        "        else:\n",
        "            losses += 1\n",
        "\n",
        "        player_sums.append(state[0])  # Final player sum\n",
        "\n",
        "    print(\"\\nDetailed Evaluation Results:\")\n",
        "    print(f\"Number of Episodes: {n_episodes}\")\n",
        "    print(f\"Win Rate: {wins/n_episodes*100:.1f}%  ({wins}/{n_episodes})\")\n",
        "    print(f\"Draw Rate: {draws/n_episodes*100:.1f}%  ({draws}/{n_episodes})\")\n",
        "    print(f\"Loss Rate: {losses/n_episodes*100:.1f}%  ({losses}/{n_episodes})\")\n",
        "    print(f\"Average Reward: {np.mean(total_rewards):.3f}\")\n",
        "    print(f\"Average Final Player Sum: {np.mean(player_sums):.1f}\")\n",
        "\n",
        "    return total_rewards, player_sums\n",
        "\n",
        "# Evaluate the trained agent\n",
        "print(\"\\nEvaluating trained agent...\")\n",
        "eval_rewards, player_sums = evaluate_agent_detailed(test_env, DQN_Agent, n_episodes=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2QJAaa2fvcc"
      },
      "source": [
        "### Visualizing the Agent's Learning with Gymnasium's RGB Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwyJyBPkfl39",
        "outputId": "b2ab5c38-8be3-4791-8162-8b739ea99621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/gym_monitor_output folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Detailed Evaluation Results:\n",
            "Number of Episodes: 200\n",
            "Win Rate: 35.0%  (70/200)\n",
            "Draw Rate: 9.5%  (19/200)\n",
            "Loss Rate: 55.5%  (111/200)\n",
            "Average Reward: -0.205\n",
            "Average Final Player Sum: 19.5\n"
          ]
        }
      ],
      "source": [
        "# Uses the Gym Monitor wrapper to evalaute the agent and record video\n",
        "# only one video will be saved\n",
        "# video of the final episode with the episode trigger\n",
        "test_env = gym.wrappers.RecordVideo(\n",
        "    test_env, \"./gym_monitor_output\", episode_trigger=lambda x: x == 0)\n",
        "\n",
        "evaluate_agent_detailed(test_env, DQN_Agent)\n",
        "\n",
        "test_env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PlJGfS08nMwd"
      },
      "outputs": [],
      "source": [
        "# play a video using a path to the video\n",
        "from IPython.display import Video\n",
        "from base64 import b64encode\n",
        "\n",
        "def show_video(video_path):\n",
        "    video_file = Video(video_path, embed=True)\n",
        "    display(video_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "oMwgylKlnaDn",
        "outputId": "6e52b1a4-7a96-4029-fa08-0c5e289e134e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video controls  >\n",
              " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# visualizing the rl-video-episode-0.mp4 in the gym_monitor_output\n",
        "show_video(\"./gym_monitor_output/rl-video-episode-0.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpSdmCd8jOY_"
      },
      "source": [
        "## Strategy Analysis and Interactive Human Feedback Loop with A.I Recommendation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcTSx1uqjaNj"
      },
      "source": [
        "### Strategy Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m6LhAQLfZCX",
        "outputId": "4b243cd5-aaf1-40b0-e537-88e7d9e7c496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Strategy Analysis:\n",
            "Player Sum | Dealer Card | Action\n",
            "-----------------------------------\n",
            "    16     |     10      |  Hit  \n",
            "    12     |      6      | Stand \n",
            "    18     |      9      | Stand \n",
            "    11     |     10      |  Hit  \n",
            "    15     |      7      |  Hit  \n"
          ]
        }
      ],
      "source": [
        "def analyze_strategy(agent):\n",
        "    # Common situations in blackjack\n",
        "    test_states = [\n",
        "        (16, 10, 0),  # Hard 16 vs dealer 10\n",
        "        (12, 6, 0),   # Hard 12 vs dealer 6\n",
        "        (18, 9, 0),   # Hard 18 vs dealer 9\n",
        "        (11, 10, 0),  # Hard 11 vs dealer 10\n",
        "        (15, 7, 0),   # Hard 15 vs dealer 7\n",
        "    ]\n",
        "\n",
        "    print(\"\\nStrategy Analysis:\")\n",
        "    print(\"Player Sum | Dealer Card | Action\")\n",
        "    print(\"-\" * 35)\n",
        "\n",
        "    for player_sum, dealer_card, usable_ace in test_states:\n",
        "        state = np.array([player_sum, dealer_card, usable_ace])\n",
        "        with torch.no_grad():\n",
        "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "            action = agent.policy_net(state_tensor).argmax().item()\n",
        "            action_name = \"Hit\" if action == 1 else \"Stand\"\n",
        "            print(f\"{player_sum:^10} | {dealer_card:^11} | {action_name:^6}\")\n",
        "\n",
        "# Run strategy analysis\n",
        "analyze_strategy(DQN_Agent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVFaJR1rjcSx"
      },
      "source": [
        "### Interactive Human Feedback Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3dEFiVDf_W9",
        "outputId": "db394e10-45e1-48de-912b-2104b6d8a0c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting interactive learning blackjack game...\n",
            "\n",
            "Welcome to Interactive Learning Blackjack!\n",
            "The AI will learn from your games.\n",
            "\n",
            "Dealer shows: [6, ?]\n",
            "Your cards: [1, 7]\n",
            "Your total: 18\n",
            "\n",
            "AI Recommends: Stand (Confidence: 0.52)\n",
            "\n",
            "Your action (H/S): S\n",
            "Dealer hits: [6, 12, 2] (Total: 18)\n",
            "\n",
            "Final hands:\n",
            "Dealer: [6, 12, 2] (Total: 18)\n",
            "Player: [1, 7] (Total: 18)\n",
            "Push (tie)!\n",
            "\n",
            "Current Stats:\n",
            "Games Played: 1\n",
            "Win Rate: 0.0%\n",
            "\n",
            "Play again? (Y/N): Y\n",
            "\n",
            "Dealer shows: [4, ?]\n",
            "Your cards: [12, 8]\n",
            "Your total: 18\n",
            "\n",
            "AI Recommends: Stand (Confidence: 0.71)\n",
            "\n",
            "Your action (H/S): S\n",
            "Dealer hits: [4, 1, 6] (Total: 21)\n",
            "\n",
            "Final hands:\n",
            "Dealer: [4, 1, 6] (Total: 21)\n",
            "Player: [12, 8] (Total: 18)\n",
            "Dealer wins!\n",
            "\n",
            "Current Stats:\n",
            "Games Played: 2\n",
            "Win Rate: 0.0%\n",
            "\n",
            "Play again? (Y/N): N\n",
            "\n",
            "Final Stats:\n",
            "Games Played: 2\n",
            "Wins: 0\n",
            "Losses: 1\n",
            "Draws: 1\n",
            "Win Rate: 0.0%\n",
            "\n",
            "Improved model saved!\n"
          ]
        }
      ],
      "source": [
        "def print_cards(cards, hidden=False):\n",
        "    if hidden:\n",
        "        return f\"[{cards[0]}, ?]\"\n",
        "    return str(cards)\n",
        "\n",
        "def get_card_value(card):\n",
        "    if card == 1:  # Ace\n",
        "        return 11\n",
        "    return min(card, 10)\n",
        "\n",
        "def calculate_hand_value(cards):\n",
        "    value = sum(get_card_value(card) for card in cards)\n",
        "    num_aces = cards.count(1)\n",
        "\n",
        "    # Adjust for aces\n",
        "    while value > 21 and num_aces:\n",
        "        value -= 10\n",
        "        num_aces -= 1\n",
        "\n",
        "    return value\n",
        "\n",
        "def play_interactive_blackjack_with_learning(agent):\n",
        "    print(\"\\nWelcome to Interactive Learning Blackjack!\")\n",
        "    print(\"The AI will learn from your games.\")\n",
        "\n",
        "    game_memory = []  # Store game experiences\n",
        "    stats = {'games': 0, 'wins': 0, 'losses': 0, 'draws': 0}\n",
        "\n",
        "    while True:\n",
        "        player_cards = []\n",
        "        dealer_cards = []\n",
        "        deck = list(range(1, 14)) * 4\n",
        "        random.shuffle(deck)\n",
        "\n",
        "        # Initial deal\n",
        "        player_cards.extend([deck.pop(), deck.pop()])\n",
        "        dealer_cards.extend([deck.pop(), deck.pop()])\n",
        "\n",
        "        game_states = []  # Store states for this game\n",
        "\n",
        "        while True:\n",
        "            print(\"\\nDealer shows:\", print_cards(dealer_cards, hidden=True))\n",
        "            print(\"Your cards:\", print_cards(player_cards))\n",
        "            player_value = calculate_hand_value(player_cards)\n",
        "            print(f\"Your total: {player_value}\")\n",
        "\n",
        "            if player_value > 21:\n",
        "                print(\"Bust! You lose.\")\n",
        "                stats['losses'] += 1\n",
        "                break\n",
        "\n",
        "            # Current state\n",
        "            current_state = np.array([player_value, get_card_value(dealer_cards[0]), 1 in player_cards])\n",
        "\n",
        "            # Get AI recommendation\n",
        "            with torch.no_grad():\n",
        "                state_tensor = torch.FloatTensor(current_state).unsqueeze(0)\n",
        "                q_values = agent.policy_net(state_tensor)\n",
        "                ai_action = q_values.argmax().item()\n",
        "                confidence = torch.softmax(q_values, dim=1)[0]\n",
        "                ai_recommendation = \"Hit\" if ai_action == 1 else \"Stand\"\n",
        "                print(f\"\\nAI Recommends: {ai_recommendation} (Confidence: {confidence[ai_action]:.2f})\")\n",
        "\n",
        "            action = input(\"\\nYour action (H/S): \").upper()\n",
        "            while action not in ['H', 'S']:\n",
        "                action = input(\"Invalid input. Please enter H or S: \").upper()\n",
        "\n",
        "            # Store state and action\n",
        "            game_states.append((\n",
        "                current_state,\n",
        "                1 if action == 'H' else 0,\n",
        "                player_value\n",
        "            ))\n",
        "\n",
        "            if action == 'H':\n",
        "                player_cards.append(deck.pop())\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        # Game ended, calculate final reward\n",
        "        final_player_value = calculate_hand_value(player_cards)\n",
        "        dealer_value = play_dealer_hand(dealer_cards, deck)\n",
        "\n",
        "        if final_player_value <= 21:\n",
        "            print(\"\\nFinal hands:\")\n",
        "            print(f\"Dealer: {print_cards(dealer_cards)} (Total: {dealer_value})\")\n",
        "            print(f\"Player: {print_cards(player_cards)} (Total: {final_player_value})\")\n",
        "\n",
        "            if dealer_value > 21:\n",
        "                print(\"Dealer busts! You win!\")\n",
        "                reward = 1.0\n",
        "                stats['wins'] += 1\n",
        "            elif dealer_value > final_player_value:\n",
        "                print(\"Dealer wins!\")\n",
        "                reward = -1.0\n",
        "                stats['losses'] += 1\n",
        "            elif dealer_value < final_player_value:\n",
        "                print(\"You win!\")\n",
        "                reward = 1.0\n",
        "                stats['wins'] += 1\n",
        "            else:\n",
        "                print(\"Push (tie)!\")\n",
        "                reward = 0.0\n",
        "                stats['draws'] += 1\n",
        "        else:\n",
        "            reward = -1.0\n",
        "\n",
        "        # Store experiences for learning\n",
        "        for state, action, value in game_states:\n",
        "            agent.memory.push(state, action, reward, state, True)\n",
        "            # Train on a batch\n",
        "            if len(agent.memory) >= agent.batch_size:\n",
        "                loss = agent.train_step()\n",
        "                if loss:\n",
        "                    print(f\"Training loss: {loss:.4f}\")\n",
        "\n",
        "        stats['games'] += 1\n",
        "        print(\"\\nCurrent Stats:\")\n",
        "        print(f\"Games Played: {stats['games']}\")\n",
        "        print(f\"Win Rate: {stats['wins']/stats['games']*100:.1f}%\")\n",
        "\n",
        "        play_again = input(\"\\nPlay again? (Y/N): \").upper()\n",
        "        if play_again != 'Y':\n",
        "            break\n",
        "\n",
        "    print(\"\\nFinal Stats:\")\n",
        "    print(f\"Games Played: {stats['games']}\")\n",
        "    print(f\"Wins: {stats['wins']}\")\n",
        "    print(f\"Losses: {stats['losses']}\")\n",
        "    print(f\"Draws: {stats['draws']}\")\n",
        "    print(f\"Win Rate: {stats['wins']/stats['games']*100:.1f}%\")\n",
        "\n",
        "    # Save the improved model\n",
        "    torch.save({\n",
        "        'policy_net_state_dict': agent.policy_net.state_dict(),\n",
        "        'optimizer_state_dict': agent.optimizer.state_dict(),\n",
        "        'epsilon': agent.epsilon,\n",
        "    }, 'blackjack_dqn_improved.pth')\n",
        "    print(\"\\nImproved model saved!\")\n",
        "\n",
        "# Helper function for dealer's turn\n",
        "def play_dealer_hand(dealer_cards, deck):\n",
        "    dealer_value = calculate_hand_value(dealer_cards)\n",
        "    while dealer_value < 17:\n",
        "        dealer_cards.append(deck.pop())\n",
        "        dealer_value = calculate_hand_value(dealer_cards)\n",
        "        print(f\"Dealer hits: {print_cards(dealer_cards)} (Total: {dealer_value})\")\n",
        "    return dealer_value\n",
        "\n",
        "# Start the learning interactive game\n",
        "print(\"\\nStarting interactive learning blackjack game...\")\n",
        "play_interactive_blackjack_with_learning(DQN_Agent)"
      ]
    }
  ]
}